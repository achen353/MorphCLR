{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to fine-tune the model with linear evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUemQib7ZE4D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "import gdown\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = {\n",
    "    # MorphCLRSingle checkpoints\n",
    "    \"canny_single_pretrained\": \"stl10_canny_single_pretrained_resnet18_0050\",\n",
    "    \"canny_single_random\": \"stl10_canny_single_random_resnet18_0050\",\n",
    "    \"dexined_single_pretrained\": \"stl10_dexined_single_pretrained_resnet18_0050\",\n",
    "    \"dexined_single_random\": \"stl10_dexined_single_random_resnet18_0050\",\n",
    "    \"baseline_pretrained\": \"stl10_pretrained_resnet18_0050\",\n",
    "    \"baseline_random\": \"stl10_random_resnet18_0050\",\n",
    "    # MorphCLRDual checkpoints\n",
    "    \"canny_dual_pretrained\": \"stl10_canny_dual_pretrained_resnet18_0050\",\n",
    "    \"canny_dual_random\": \"stl10_canny_dual_random_resnet18_0050\",\n",
    "    \"dexined_dual_pretrained\": \"stl10_dexined_dual_pretrained_resnet18_0050\",\n",
    "    \"dexined_dual_random\": \"stl10_dexined_dual_random_resnet18_0050\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Classification Layer and Save the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_nypQVEv-hn"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from Edge_images.generate_datasets import (\n",
    "    STL10,\n",
    "    CannyDataset,\n",
    "    DexiNedTrainDataset,\n",
    "    DexiNedTestDataset,\n",
    "    DualDataset,\n",
    ")\n",
    "from models.morphclr import MorphCLRSingleEval, MorphCLRDualEval\n",
    "from utils import save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDfbL3w_Z0Od",
    "outputId": "7532966e-1c4a-4641-c928-4cda14c53389"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../datasets\"\n",
    "checkpoint_root = \"../runs\"\n",
    "print(\"Data root: \", data_root)\n",
    "print(\"Checkpoint root: \", checkpoint_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfIPl0G6_RrT"
   },
   "outputs": [],
   "source": [
    "def get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = datasets.STL10(\n",
    "        \"../datasets\", split=\"train\", download=download, transform=transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.STL10(\n",
    "        \"../datasets\", split=\"test\", download=download, transform=transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2 * batch_size,\n",
    "        num_workers=10,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def get_stl10_canny_dual_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = DualDataset(\n",
    "        CannyDataset(root=data_root, split=\"train\", transform=transforms.ToTensor()),\n",
    "        STL10(root=data_root, split=\"train\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    test_dataset = DualDataset(\n",
    "        CannyDataset(root=data_root, split=\"test\", transform=transforms.ToTensor()),\n",
    "        STL10(root=data_root, split=\"test\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2 * batch_size,\n",
    "        num_workers=10,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_stl10_dexined_dual_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = DualDataset(\n",
    "        DexiNedTrainDataset(\n",
    "            csv_file=\"../Edge_images/Dexi/train/labels.csv\",\n",
    "            root_dir=\"../Edge_images/Dexi/train\",\n",
    "            transform=transforms.ToTensor(),\n",
    "        ),\n",
    "        STL10(root=data_root, split=\"train\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    test_dataset = DualDataset(\n",
    "        DexiNedTestDataset(\n",
    "            csv_file=\"../Edge_images/Dexi/test/labels.csv\",\n",
    "            root_dir=\"../Edge_images/Dexi/test\",\n",
    "            transform=transforms.ToTensor(),\n",
    "        ),\n",
    "        STL10(root=data_root, split=\"test\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2 * batch_size,\n",
    "        num_workers=10,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"resnet18\"\n",
    "print(\"Backbone arch: \", arch)\n",
    "\n",
    "exps = [\n",
    "    \"baseline_pretrained\",\n",
    "    \"baseline_random\",\n",
    "    \"canny_single_pretrained\",\n",
    "    \"canny_single_random\",\n",
    "    \"dexined_single_pretrained\",\n",
    "    \"dexined_single_random\",\n",
    "    \"canny_dual_pretrained\",\n",
    "    \"canny_dual_random\",\n",
    "    \"dexined_dual_pretrained\",\n",
    "    \"dexined_dual_random\",\n",
    "]\n",
    "\n",
    "with open(\"morphclr_finetune_result.csv\", \"a\") as f:\n",
    "    f.write(\"exp,top_1_train_acc,top_1_test_acc,top_5_test_acc\\n\")\n",
    "\n",
    "for exp in exps:\n",
    "    print(\"Experiment: \", exp)\n",
    "\n",
    "    if exp.startswith(\"baseline\"):\n",
    "        if arch == \"resnet18\":\n",
    "            eval_model = torchvision.models.resnet18(pretrained=False).to(device)\n",
    "        elif arch == \"resnet50\":\n",
    "            eval_model = torchvision.models.resnet50(pretrained=False).to(device)\n",
    "        \n",
    "        checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root, checkpoints[exp], \"checkpoint_\" + checkpoints[exp] + \".pth.tar\"\n",
    "        )\n",
    "        checkpoint = torch.load(\n",
    "            checkpoint_file_path, map_location=device\n",
    "        )\n",
    "        \n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        for k in list(state_dict.keys()):\n",
    "            if k.startswith(\"backbone.\"):\n",
    "                if k.startswith(\"backbone\") and not k.startswith(\"backbone.fc\"):\n",
    "                    # remove prefix\n",
    "                    state_dict[k[len(\"backbone.\") :]] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "        \n",
    "        log = eval_model.load_state_dict(state_dict, strict=False)\n",
    "        assert log.missing_keys == [\"fc.weight\", \"fc.bias\"]\n",
    "        \n",
    "    elif \"single\" in exp:\n",
    "        init_type = exp.split(\"_\")[-1]\n",
    "        edge_checkpoint_key, non_edge_checkpoint_key = exp, \"baseline_{}\".format(init_type)\n",
    "        edge_checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root, checkpoints[exp], \"checkpoint_\" + checkpoints[exp] + \".pth.tar\"\n",
    "        )\n",
    "        non_edge_checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root,\n",
    "            checkpoints[non_edge_checkpoint_key],\n",
    "            \"checkpoint_\" + checkpoints[non_edge_checkpoint_key] + \".pth.tar\",\n",
    "        )\n",
    "        eval_model = MorphCLRSingleEval(\n",
    "            arch, edge_checkpoint_file_path, non_edge_checkpoint_file_path, device\n",
    "        )\n",
    "    else:\n",
    "        checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root,\n",
    "            checkpoints[exp],\n",
    "            \"checkpoint_\" + checkpoints[exp] + \".pth.tar\",\n",
    "        )\n",
    "        eval_model = MorphCLRDualEval(arch, checkpoint_file_path, device)\n",
    "\n",
    "    if exp.startswith(\"baseline\"):\n",
    "        get_data_loader_fn = get_stl10_data_loaders\n",
    "    elif \"canny\" in exp:\n",
    "        get_data_loader_fn = get_stl10_canny_dual_data_loaders\n",
    "    else:\n",
    "        get_data_loader_fn = get_stl10_dexined_dual_data_loaders\n",
    "\n",
    "    train_loader, test_loader = get_data_loader_fn(download=True)\n",
    "\n",
    "    # freeze all layers but the last fc\n",
    "    for name, param in eval_model.named_parameters():\n",
    "        if exp.startswith(\"baseline\"):\n",
    "            trainable_param_names = [\"fc.weight\", \"fc.bias\"]\n",
    "        else:\n",
    "            trainable_param_names = [\"linear.weight\", \"linear.bias\"]\n",
    "        if name not in trainable_param_names:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    parameters = list(filter(lambda p: p.requires_grad, eval_model.parameters()))\n",
    "    assert len(parameters) == 2\n",
    "\n",
    "    optimizer = torch.optim.Adam(eval_model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        eval_model.train()\n",
    "        top1_train_accuracy = 0\n",
    "        for counter, batch_data in enumerate(train_loader):\n",
    "            if exp.startswith(\"baseline\"):\n",
    "                x_batch, y_batch = batch_data\n",
    "                x_batch = x_batch.to(device)\n",
    "            else:\n",
    "                x_edge_batch, x_non_edge_batch, y_batch = batch_data\n",
    "                x_edge_batch = x_edge_batch.to(device)\n",
    "                if len(x_edge_batch.shape) == 3:\n",
    "                    x_edge_batch = x_edge_batch.unsqueeze(1)\n",
    "                # If the image is of grayscale, repeat the dimension to create 3 channels\n",
    "                if x_edge_batch.shape[1] == 1:\n",
    "                    x_edge_batch = x_edge_batch.repeat(1, 3, 1, 1)\n",
    "                x_non_edge_batch = x_non_edge_batch.to(device)\n",
    "                x_batch = torch.stack([x_edge_batch, x_non_edge_batch], dim=0)\n",
    "            \n",
    "            y_batch = y_batch.flatten().to(device)\n",
    "\n",
    "            logits = eval_model(x_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "            top1_train_accuracy += top1[0]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        top1_train_accuracy /= len(train_loader.dataset)\n",
    "\n",
    "        eval_model.eval()\n",
    "        top1_accuracy = 0\n",
    "        top5_accuracy = 0\n",
    "        for counter, batch_data in enumerate(test_loader):\n",
    "            if exp.startswith(\"baseline\"):\n",
    "                x_batch, y_batch = batch_data\n",
    "                x_batch = x_batch.to(device)\n",
    "            else:\n",
    "                x_edge_batch, x_non_edge_batch, y_batch = batch_data\n",
    "                x_edge_batch = x_edge_batch.to(device)\n",
    "                if len(x_edge_batch.shape) == 3:\n",
    "                    x_edge_batch = x_edge_batch.unsqueeze(1)\n",
    "                # If the image is of grayscale, repeat the dimension to create 3 channels\n",
    "                if x_edge_batch.shape[1] == 1:\n",
    "                    x_edge_batch = x_edge_batch.repeat(1, 3, 1, 1)\n",
    "                x_non_edge_batch = x_non_edge_batch.to(device)\n",
    "                x_batch = torch.stack([x_edge_batch, x_non_edge_batch], dim=0)\n",
    "            \n",
    "            y_batch = y_batch.flatten().to(device)\n",
    "\n",
    "            logits = eval_model(x_batch)\n",
    "\n",
    "            top1, top5 = accuracy(logits, y_batch, topk=(1, 5))\n",
    "            top1_accuracy += top1[0]\n",
    "            top5_accuracy += top5[0]\n",
    "\n",
    "        top1_accuracy /= len(test_loader.dataset)\n",
    "        top5_accuracy /= len(test_loader.dataset)\n",
    "        print(\n",
    "            \"Epoch {}\\tTop1 Train accuracy {}\\tTop1 Test accuracy: {}\\tTop5 test acc: {}\".format(\n",
    "                epoch, top1_train_accuracy.item(), top1_accuracy.item(), top5_accuracy.item()\n",
    "            )\n",
    "        )\n",
    "\n",
    "    with open(\"morphclr_finetune_result.csv\", \"a\") as f:\n",
    "        f.write(\"{},{},{},{}\\n\".format(exp, top1_train_accuracy.item(), top1_accuracy.item(), top5_accuracy.item()))\n",
    "    \n",
    "    lr_checkpoint_name = \"morphclr_{}_{}_50-epochs_stl10_{}-epochs.pt\".format(exp, arch, epochs)\n",
    "\n",
    "    save_checkpoint(\n",
    "        {\n",
    "            \"epoch\": epochs,\n",
    "            \"arch\": \"resnet18\",\n",
    "            \"state_dict\": eval_model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        },\n",
    "        is_best=False,\n",
    "        filename=os.path.join(\"../checkpoints/finetune/\", lr_checkpoint_name),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('morphclr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2dd6e96f481d38e9b0a82cd02dc94f00b72e4f2b692d7959cb897060908b8acd"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "149b9ce8fb68473a837a77431c12281a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
       "IPY_MODEL_60c6150177694717a622936b830427b5"
      ],
      "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
     }
    },
    "5901c2829a554c8ebbd5926610088041": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60c6150177694717a622936b830427b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
      "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
     }
    },
    "88cd3db2831e4c13a4a634709700d6b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "957362a11d174407979cf17012bf9208": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4f82234388e4701a02a9f68a177193a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a88c31d74f5c40a2b24bcff5a35d216c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
      "value": 1
     }
    },
    "dba019efadee4fdc8c799f309b9a7e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
