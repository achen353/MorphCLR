{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to fine-tune the model with linear evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUemQib7ZE4D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "import gdown\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = {\n",
    "    # MorphCLRSingle checkpoints\n",
    "    \"canny_single_pretrained\": \"stl10_canny_single_pretrained_resnet18_0050\",\n",
    "    \"canny_single_random\": \"stl10_canny_single_random_resnet18_0050\",\n",
    "    \"dexined_single_pretrained\": \"stl10_dexined_single_pretrained_resnet18_0050\",\n",
    "    \"dexined_single_random\": \"stl10_dexined_single_random_resnet18_0050\",\n",
    "    \"baseline_pretrained\": \"stl10_pretrained_resnet18_0050\",\n",
    "    \"baseline_random\": \"stl10_random_resnet18_0050\",\n",
    "    \"baseline_canny_random\": \"stl10_canny_single_random_resnet18_0050\",\n",
    "    \"baseline_dexined_random\": \"stl10_dexined_single_random_resnet18_0050\",\n",
    "    # MorphCLRDual checkpoints\n",
    "    \"canny_dual_pretrained\": \"stl10_canny_dual_pretrained_resnet18_0050\",\n",
    "    \"canny_dual_random\": \"stl10_canny_dual_random_resnet18_0050\",\n",
    "    \"dexined_dual_pretrained\": \"stl10_dexined_dual_pretrained_resnet18_0050\",\n",
    "    \"dexined_dual_random\": \"stl10_dexined_dual_random_resnet18_0050\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Classification Layer and Save the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from matplotlib import cm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from Edge_images.generate_datasets import (\n",
    "    STL10,\n",
    "    CannyDataset,\n",
    "    DexiNedTrainDataset,\n",
    "    DexiNedTestDataset,\n",
    "    DualDataset,\n",
    ")\n",
    "from models.morphclr import MorphCLRBase, MorphCLRSingleEval, MorphCLRDualEval\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDfbL3w_Z0Od",
    "outputId": "7532966e-1c4a-4641-c928-4cda14c53389"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../datasets\"\n",
    "checkpoint_root = \"../runs\"\n",
    "print(\"Data root: \", data_root)\n",
    "print(\"Checkpoint root: \", checkpoint_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfIPl0G6_RrT"
   },
   "outputs": [],
   "source": [
    "def get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = datasets.STL10(\n",
    "        \"../datasets\", split=\"train\", download=download, transform=transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.STL10(\n",
    "        \"../datasets\", split=\"test\", download=download, transform=transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2 * batch_size,\n",
    "        num_workers=10,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_stl10_canny_dual_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = DualDataset(\n",
    "        CannyDataset(root=data_root, split=\"train\", transform=transforms.ToTensor()),\n",
    "        STL10(root=data_root, split=\"train\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    test_dataset = DualDataset(\n",
    "        CannyDataset(root=data_root, split=\"test\", transform=transforms.ToTensor()),\n",
    "        STL10(root=data_root, split=\"test\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2 * batch_size,\n",
    "        num_workers=10,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_stl10_dexined_dual_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = DualDataset(\n",
    "        DexiNedTrainDataset(\n",
    "            csv_file=\"../Edge_images/Dexi/train/labels.csv\",\n",
    "            root_dir=\"../Edge_images/Dexi/train\",\n",
    "            transform=transforms.ToTensor(),\n",
    "        ),\n",
    "        STL10(root=data_root, split=\"train\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    test_dataset = DualDataset(\n",
    "        DexiNedTestDataset(\n",
    "            csv_file=\"../Edge_images/Dexi/test/labels.csv\",\n",
    "            root_dir=\"../Edge_images/Dexi/test\",\n",
    "            transform=transforms.ToTensor(),\n",
    "        ),\n",
    "        STL10(root=data_root, split=\"test\", transform=transforms.ToTensor()),\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2 * batch_size,\n",
    "        num_workers=10,\n",
    "        drop_last=False,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"resnet18\"\n",
    "print(\"Backbone arch: \", arch)\n",
    "\n",
    "exps = [\n",
    "    \"baseline_pretrained\",\n",
    "    \"baseline_random\",\n",
    "    \"baseline_canny_random\",\n",
    "    \"baseline_dexined_random\",\n",
    "    \"canny_single_pretrained\",\n",
    "    \"canny_single_random\",\n",
    "    \"dexined_single_pretrained\",\n",
    "    \"dexined_single_random\",\n",
    "    \"canny_dual_pretrained\",\n",
    "    \"canny_dual_random\",\n",
    "    \"dexined_dual_pretrained\",\n",
    "    \"dexined_dual_random\",\n",
    "]\n",
    "\n",
    "for exp in exps:\n",
    "    print(\"[INFO] Experiment: \", exp)\n",
    "\n",
    "    if exp.startswith(\"baseline\"):\n",
    "        if arch == \"resnet18\":\n",
    "            eval_model = torchvision.models.resnet18(pretrained=False).to(device)\n",
    "        elif arch == \"resnet50\":\n",
    "            eval_model = torchvision.models.resnet50(pretrained=False).to(device)\n",
    "\n",
    "        checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root,\n",
    "            checkpoints[exp],\n",
    "            \"checkpoint_\" + checkpoints[exp] + \".pth.tar\",\n",
    "        )\n",
    "        checkpoint = torch.load(checkpoint_file_path, map_location=device)\n",
    "\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        for k in list(state_dict.keys()):\n",
    "            if k.startswith(\"backbone.\"):\n",
    "                if k.startswith(\"backbone\") and not k.startswith(\"backbone.fc\"):\n",
    "                    # remove prefix\n",
    "                    state_dict[k[len(\"backbone.\") :]] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "\n",
    "        log = eval_model.load_state_dict(state_dict, strict=False)\n",
    "        assert log.missing_keys == [\"fc.weight\", \"fc.bias\"]\n",
    "\n",
    "        eval_model.fc = nn.Identity()\n",
    "\n",
    "    elif \"single\" in exp:\n",
    "        init_type = exp.split(\"_\")[-1]\n",
    "        edge_checkpoint_key, non_edge_checkpoint_key = exp, \"baseline_{}\".format(\n",
    "            init_type\n",
    "        )\n",
    "        edge_checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root,\n",
    "            checkpoints[exp],\n",
    "            \"checkpoint_\" + checkpoints[exp] + \".pth.tar\",\n",
    "        )\n",
    "        non_edge_checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root,\n",
    "            checkpoints[non_edge_checkpoint_key],\n",
    "            \"checkpoint_\" + checkpoints[non_edge_checkpoint_key] + \".pth.tar\",\n",
    "        )\n",
    "        eval_model = MorphCLRSingleEval(\n",
    "            base_model=arch,\n",
    "            edge_checkpoint_file_path=edge_checkpoint_file_path,\n",
    "            non_edge_checkpoint_file_path=non_edge_checkpoint_file_path,\n",
    "            device=device,\n",
    "            return_embedding=True,\n",
    "        )\n",
    "    else:\n",
    "        checkpoint_file_path = os.path.join(\n",
    "            checkpoint_root,\n",
    "            checkpoints[exp],\n",
    "            \"checkpoint_\" + checkpoints[exp] + \".pth.tar\",\n",
    "        )\n",
    "        eval_model = MorphCLRDualEval(\n",
    "            base_model=arch,\n",
    "            checkpoint_file_path=checkpoint_file_path,\n",
    "            device=device,\n",
    "            return_embedding=True,\n",
    "        )\n",
    "\n",
    "    if exp.startswith(\"baseline\"):\n",
    "        get_data_loader_fn = get_stl10_data_loaders\n",
    "    elif \"canny\" in exp:\n",
    "        get_data_loader_fn = get_stl10_canny_dual_data_loaders\n",
    "    else:\n",
    "        get_data_loader_fn = get_stl10_dexined_dual_data_loaders\n",
    "\n",
    "    train_loader, test_loader = get_data_loader_fn(download=True)\n",
    "\n",
    "    # freeze all layers\n",
    "    for name, param in eval_model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    epochs = 1\n",
    "    n_class = 10\n",
    "    n_points_per_class = 800\n",
    "    sample_size = 80\n",
    "    embeddings_by_cls = {c: [] for c in range(n_class)}\n",
    "\n",
    "    eval_model.eval()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for counter, batch_data in enumerate(tqdm(test_loader)):\n",
    "            if exp.startswith(\"baseline\"):\n",
    "                x_batch, y_batch = batch_data\n",
    "                x_batch = x_batch.to(device)\n",
    "            else:\n",
    "                x_edge_batch, x_non_edge_batch, y_batch = batch_data\n",
    "                x_edge_batch = x_edge_batch.to(device)\n",
    "                if len(x_edge_batch.shape) == 3:\n",
    "                    x_edge_batch = x_edge_batch.unsqueeze(1)\n",
    "                # If the image is of grayscale, repeat the dimension to create 3 channels\n",
    "                if x_edge_batch.shape[1] == 1:\n",
    "                    x_edge_batch = x_edge_batch.repeat(1, 3, 1, 1)\n",
    "                x_non_edge_batch = x_non_edge_batch.to(device)\n",
    "                x_batch = torch.stack([x_edge_batch, x_non_edge_batch], dim=0)\n",
    "\n",
    "            y_batch = y_batch.flatten().to(device)\n",
    "\n",
    "            if not issubclass(type(eval_model), MorphCLRBase):\n",
    "                embeddings = eval_model(x_batch)\n",
    "            else:\n",
    "                _, embeddings = eval_model(x_batch)\n",
    "\n",
    "            for i, c in enumerate(y_batch.detach().cpu().numpy()):\n",
    "                embeddings_by_cls[c].append(embeddings[i].detach().cpu().numpy())\n",
    "\n",
    "    for c in embeddings_by_cls.keys():\n",
    "        embeddings_by_cls[c] = np.vstack(embeddings_by_cls[c])\n",
    "        idxs = np.random.choice(range(n_points_per_class), sample_size, replace=False)\n",
    "        embeddings_by_cls[c] = embeddings_by_cls[c][idxs]\n",
    "\n",
    "    # Prepare data for t-SNE plots\n",
    "    tsne_embeddings = np.concatenate([embeddings_by_cls[c] for c in range(n_class)])\n",
    "    tsne_targets = np.array(\n",
    "        list(itertools.chain(*[[c] * sample_size for c in range(n_class)]))\n",
    "    )\n",
    "\n",
    "    # 2D t-SNE plots\n",
    "    print(\"[INFO] Fitting 2D t-SNE plot.\")\n",
    "    tsne = TSNE(2, verbose=1)\n",
    "    tsne_proj = tsne.fit_transform(tsne_embeddings)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    cmap = cm.get_cmap(\"tab20\")\n",
    "    num_categories = 10\n",
    "    for lab in range(num_categories):\n",
    "        indices = tsne_targets == lab\n",
    "        ax.scatter(\n",
    "            tsne_proj[indices, 0],\n",
    "            tsne_proj[indices, 1],\n",
    "            c=np.array(cmap(lab)).reshape(1, 4),\n",
    "            label=lab + 1,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "    ax.legend(fontsize=\"large\", markerscale=2)\n",
    "    plt.savefig(\"./2d_tsne/{}.png\".format(exp), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('morphclr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2dd6e96f481d38e9b0a82cd02dc94f00b72e4f2b692d7959cb897060908b8acd"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "149b9ce8fb68473a837a77431c12281a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
       "IPY_MODEL_60c6150177694717a622936b830427b5"
      ],
      "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
     }
    },
    "5901c2829a554c8ebbd5926610088041": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60c6150177694717a622936b830427b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
      "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
     }
    },
    "88cd3db2831e4c13a4a634709700d6b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "957362a11d174407979cf17012bf9208": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4f82234388e4701a02a9f68a177193a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a88c31d74f5c40a2b24bcff5a35d216c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
      "value": 1
     }
    },
    "dba019efadee4fdc8c799f309b9a7e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
